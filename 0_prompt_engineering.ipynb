{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5be5bd5b",
   "metadata": {},
   "source": [
    "# 0. Introduction to Prompt Engineering with Bedrock\n",
    "\n",
    "This notebook will introduce you to prompt engineering concepts using Amazon Bedrock. We'll start with basic prompts and incrementally add structure and complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a5cf13",
   "metadata": {},
   "source": [
    "## Setting up Bedrock client\n",
    "\n",
    "Let's set up the Bedrock client using our utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60db5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "\n",
    "from src.utils import (\n",
    "    create_bedrock_client,\n",
    "    text_completion,\n",
    "    extract_json_from_text,\n",
    "    invoke_with_prefill,\n",
    "    CLAUDE_3_5_SONNET,\n",
    "    CLAUDE_3_5_HAIKU,\n",
    "    NOVA_LITE\n",
    ")\n",
    "\n",
    "# Create a Bedrock client\n",
    "bedrock_client = create_bedrock_client()\n",
    "\n",
    "# Default settings\n",
    "TEMPERATURE = 0.0  # Lower temperature = more deterministic outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879a30e6",
   "metadata": {},
   "source": [
    "## 1. Basic Prompt\n",
    "\n",
    "Let's start with a very simple prompt to understand how the model responds to basic instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1257c6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is prompt engineering?\"\n",
    "\n",
    "response = text_completion(bedrock_client, prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18a7b2",
   "metadata": {},
   "source": [
    "## 2. Defining the LLM's Role\n",
    "\n",
    "Explicitly telling the LLM to adopt a specific role or persona helps shape its responses to match the expected expertise and tone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebbc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_prompt = \"\"\"\n",
    "You are an expert in artificial intelligence and machine learning, specializing in large language models.\n",
    "\n",
    "What is prompt engineering and why is it important for working with generative AI?\n",
    "\"\"\"\n",
    "\n",
    "response = text_completion(bedrock_client, role_prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1a0c1",
   "metadata": {},
   "source": [
    "## 3. Providing Reference Context\n",
    "\n",
    "Adding specific information as context helps the model ground its responses in facts you provide rather than its own training data alone. This is essential for domain-specific tasks or when working with proprietary information.\n",
    "\n",
    "First, let's define our context as a structured object, simulating data that might come from a database or API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "new-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our context as a structured data object (could come from a database, API, etc.)\n",
    "product_context = {\n",
    "    \"name\": \"ProductX\",\n",
    "    \"type\": \"AI analytics platform\",\n",
    "    \"features\": [\n",
    "        {\"name\": \"Data Processing\", \"description\": \"Real-time processing up to 10TB/hour\"},\n",
    "        {\"name\": \"Connectivity\", \"description\": \"Support for 50+ data connectors including AWS, GCP, and Azure\"},\n",
    "        {\"name\": \"Visualization\", \"description\": \"Custom dashboard with drag-and-drop interface\"},\n",
    "        {\"name\": \"AI Capabilities\", \"description\": \"Anomaly detection with 99.7% accuracy\"},\n",
    "        {\"name\": \"Automation\", \"description\": \"Automated report generation and scheduling\"}\n",
    "    ],\n",
    "    \"pricing\": [\n",
    "        {\"tier\": \"Basic\", \"cost\": \"$1,000/month\", \"users\": 5, \"storage\": \"1TB\"},\n",
    "        {\"tier\": \"Professional\", \"cost\": \"$5,000/month\", \"users\": 20, \"storage\": \"10TB\"},\n",
    "        {\"tier\": \"Enterprise\", \"cost\": \"Custom pricing\", \"users\": \"Unlimited\", \"storage\": \"Custom\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec90160",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_context_prompt = f\"\"\"\n",
    "# Product Context (JSON)\n",
    "{product_context}\n",
    "\n",
    "---\n",
    "\n",
    "Using the above product context, explain the key features of ProductX to a potential enterprise customer who needs to process 8TB of data daily and has a team of 15 analysts.\n",
    "\"\"\"\n",
    "\n",
    "response = text_completion(bedrock_client, reference_context_prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context-code",
   "metadata": {},
   "source": [
    "## 4. Adding Structure: Instructions and Rules\n",
    "\n",
    "Adding structure to your prompts using clear sections helps organize the information and makes it easier for the model to follow your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8607911",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_prompt = \"\"\"\n",
    "## Instructions\n",
    "You are an expert in generative AI. Explain the concept of prompt engineering to beginners who are just starting with large language models.\n",
    "\n",
    "## Rules\n",
    "- Keep your explanation concise and use simple language\n",
    "- Include 3-5 practical tips for effective prompt engineering\n",
    "- Provide 2 example prompts: one poorly engineered and one well-engineered\n",
    "- Explain why the well-engineered prompt would produce better results\n",
    "\"\"\"\n",
    "\n",
    "response = text_completion(bedrock_client, structured_prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef850d",
   "metadata": {},
   "source": [
    "## 5. Requesting Structured Output\n",
    "\n",
    "You can ask the model to format its response in a specific way, such as JSON, bullet points, or tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_output_prompt = \"\"\"\n",
    "## Instructions\n",
    "You are an expert in generative AI. Explain prompt engineering techniques and best practices.\n",
    "\n",
    "## Rules\n",
    "- Return your response as a JSON object with the following structure:\n",
    "  - \"definition\": A brief definition of prompt engineering\n",
    "  - \"importance\": Why prompt engineering is important\n",
    "  - \"techniques\": An array of objects, each with a \"name\" and \"description\" field for different prompt engineering techniques\n",
    "  - \"examples\": An array of objects, each with a \"good_prompt\", \"bad_prompt\", and \"explanation\" field\n",
    "\n",
    "- Return the JSON inside ```json code blocks\n",
    "\"\"\"\n",
    "\n",
    "json_response = text_completion(bedrock_client, structured_output_prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(json_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c8d03e",
   "metadata": {},
   "source": [
    "## 5.1. Extracting and Using the JSON Output\n",
    "\n",
    "Let's extract the JSON from the response and use it in our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e56cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and parse the JSON\n",
    "try:\n",
    "    json_data = extract_json_from_text(json_response)\n",
    "    \n",
    "    # Access specific fields\n",
    "    print(\"Definition of prompt engineering:\")\n",
    "    print(json_data[\"definition\"])\n",
    "    print(\"\\nPrompt engineering techniques:\")\n",
    "    for technique in json_data[\"techniques\"]:\n",
    "        print(f\"- {technique['name']}: {technique['description']}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error extracting JSON: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b24ad0",
   "metadata": {},
   "source": [
    "## 6. Response Prefilling\n",
    "\n",
    "Response prefilling lets you start the model's response with specific text, which can help ensure you get the format you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "## Instructions\n",
    "You are an expert in generative AI. Create a cheat sheet for prompt engineering techniques.\n",
    "\n",
    "## Rules\n",
    "- Format your response as a JSON object\n",
    "- Include techniques, each with a name, description, and example\n",
    "\"\"\"\n",
    "\n",
    "# Prefill the response to ensure we get the format we want - avoid trailing whitespace!\n",
    "prefill = \"\"\"```json\n",
    "{\n",
    "  \"prompt_engineering_techniques\": [\n",
    "    {\n",
    "      \"name\":\"\"\"\n",
    "\n",
    "completion = invoke_with_prefill(bedrock_client, prompt, prefill, model_id=NOVA_LITE, temperature=TEMPERATURE)\n",
    "\n",
    "# Combine the prefill and the completion for the full response\n",
    "full_response = prefill + completion\n",
    "print(full_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2685cfb",
   "metadata": {},
   "source": [
    "## 7. Zero-shot vs. Few-shot Learning\n",
    "\n",
    "Let's compare zero-shot (no examples) with few-shot (providing examples) approaches for a classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot classification\n",
    "zero_shot_prompt = \"\"\"\n",
    "## Instructions\n",
    "Classify the following customer feedback as positive, negative, or neutral.\n",
    "\n",
    "## Customer feedback\n",
    "\"The product arrived on time but was missing a few parts. Customer support was helpful and sent the missing pieces quickly.\"\n",
    "\n",
    "## Rules\n",
    "- Output only one word: positive, negative, or neutral\n",
    "\"\"\"\n",
    "\n",
    "response = text_completion(bedrock_client, zero_shot_prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(\"Zero-shot classification result:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01369257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot classification with examples\n",
    "few_shot_prompt = \"\"\"\n",
    "## Instructions\n",
    "Classify the following customer feedback as positive, negative, or neutral.\n",
    "\n",
    "## Examples\n",
    "Example 1:\n",
    "\"The service was terrible and staff was rude.\"\n",
    "Classification: negative\n",
    "\n",
    "Example 2:\n",
    "\"Amazing product! Exceeded my expectations in every way.\"\n",
    "Classification: positive\n",
    "\n",
    "Example 3:\n",
    "\"The product works as described. Nothing special but does its job.\"\n",
    "Classification: neutral\n",
    "\n",
    "## Customer feedback\n",
    "\"The product arrived on time but was missing a few parts. Customer support was helpful and sent the missing pieces quickly.\"\n",
    "\n",
    "## Rules\n",
    "- Output only one word: positive, negative, or neutral\n",
    "\"\"\"\n",
    "\n",
    "response = text_completion(bedrock_client, few_shot_prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(\"Few-shot classification result:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52f0bc",
   "metadata": {},
   "source": [
    "## 8. Advanced Prompt Engineering: Chain of Thought\n",
    "\n",
    "Chain of Thought is a technique that encourages the model to break down complex reasoning into steps, which typically produces more accurate results for complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_of_thought_prompt = \"\"\"\n",
    "## Instructions\n",
    "You are a problem-solving assistant. Solve the following word problem step-by-step.\n",
    "\n",
    "## Problem\n",
    "James has 5 boxes. Each box contains 8 books. He donates 12 books to the library. \n",
    "Then he buys 3 more boxes with 8 books each. How many books does James have now?\n",
    "\n",
    "## Rules\n",
    "- Think through this problem step by step\n",
    "- Show your reasoning for each step\n",
    "- After showing your work, provide the final answer\n",
    "\"\"\"\n",
    "\n",
    "response = text_completion(bedrock_client, chain_of_thought_prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfs3f9aa",
   "metadata": {},
   "source": [
    "## 9. Self-Verification\n",
    "\n",
    "Self-verification is a powerful technique where you ask the model to verify its own output. This is especially useful for tasks like code generation or SQL queries where correctness is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4353caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_verification_prompt = \"\"\"\n",
    "## Instructions\n",
    "You are a SQL expert. Convert the following natural language question into a SQL query for a database containing customer and order information.\n",
    "\n",
    "## Database Schema\n",
    "- customers(id, name, email, signup_date, country)\n",
    "- orders(id, customer_id, order_date, total_amount, status)\n",
    "- products(id, name, category, price)\n",
    "- order_items(order_id, product_id, quantity)\n",
    "\n",
    "## Question\n",
    "What are the top 5 countries by total order value in the last 3 months?\n",
    "\n",
    "## Rules\n",
    "1. First, think step by step about how to solve this problem\n",
    "2. Then, write the SQL query inside ```sql code blocks\n",
    "3. After writing the query, verify your solution by:\n",
    "   - Checking if it correctly addresses the original question\n",
    "   - Ensuring all necessary joins are included\n",
    "   - Confirming that date filtering is correctly applied\n",
    "   - Making sure the aggregation and sorting are appropriate\n",
    "4. If you find any issues during verification, update your query and explain the changes\n",
    "\"\"\"\n",
    "\n",
    "response = text_completion(bedrock_client, self_verification_prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ba030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just the SQL query from the response\n",
    "import re\n",
    "\n",
    "def extract_sql_from_text(text):\n",
    "    # Look for SQL code blocks\n",
    "    match = re.search(r\"```(?:sql)?\\s*\\n(.*?)```\", text, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        # If no code blocks, try to find SQL-like content directly\n",
    "        match = re.search(r\"SELECT.*?FROM.*?(?:WHERE|GROUP BY|ORDER BY|LIMIT|;)\", text, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(0).strip()\n",
    "        return \"No SQL query found\"\n",
    "\n",
    "# Extract the SQL query\n",
    "sql_query = extract_sql_from_text(response)\n",
    "print(\"Extracted SQL Query:\")\n",
    "print(\"------------------\")\n",
    "print(sql_query)\n",
    "print(\"------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f722e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple example of how you might use this query in a real application\n",
    "print(\"Example: Using the generated SQL query with a database connection\")\n",
    "print(\"\"\"\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Connect to your database\n",
    "conn = sqlite3.connect('your_database.db')\n",
    "\n",
    "# Execute the query\n",
    "result_df = pd.read_sql_query(sql_query, conn)\n",
    "\n",
    "# Display the results\n",
    "print(result_df.head())\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23277f39",
   "metadata": {},
   "source": [
    "## 10. Controlling Response Length\n",
    "\n",
    "You can instruct the model to provide responses of different lengths based on your requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2d62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_control_prompt = \"\"\"\n",
    "## Instructions\n",
    "Explain what artificial intelligence is at three different levels of detail.\n",
    "\n",
    "## Rules\n",
    "- First, give a one-sentence explanation (10-15 words)\n",
    "- Then, give a short paragraph explanation (50-75 words)\n",
    "- Finally, give a detailed explanation (150-200 words)\n",
    "- Label each section: \"One-sentence\", \"Short paragraph\", and \"Detailed explanation\"\n",
    "\"\"\"\n",
    "\n",
    "response = text_completion(bedrock_client, length_control_prompt, model_id=CLAUDE_3_5_HAIKU, temperature=TEMPERATURE)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47757d12",
   "metadata": {},
   "source": [
    "## 11. Next Steps\n",
    "\n",
    "In this notebook, we've explored several prompt engineering techniques:\n",
    "\n",
    "1. Basic prompting\n",
    "2. Defining the LLM's role\n",
    "3. Providing reference context\n",
    "4. Structuring prompts with instructions and rules\n",
    "5. Requesting structured outputs (JSON)\n",
    "6. Extracting and using JSON from responses\n",
    "7. Response prefilling\n",
    "8. Zero-shot vs. Few-shot learning\n",
    "9. Chain of thought reasoning\n",
    "10. Self-verification\n",
    "11. Controlling response length\n",
    "\n",
    "In the next notebook, we'll explore more advanced techniques like working with multimodal inputs (images and text)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0fece",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaihackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
